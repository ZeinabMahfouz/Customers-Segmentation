# ğŸ¯ Customer Segmentation & Predictive Analytics

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3.2-orange.svg)](https://scikit-learn.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.29.0-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

An end-to-end machine learning pipeline for customer segmentation using RFM analysis, K-Means clustering, and predictive modeling. Includes interactive Streamlit dashboard and Tableau-ready exports.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Pipeline Steps](#pipeline-steps)
- [Results](#results)
- [Dashboards](#dashboards)
- [Technologies](#technologies)
- [Dataset](#dataset)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸŒŸ Overview

This project implements a comprehensive customer segmentation solution that:

- **Segments customers** into distinct groups based on behavior, demographics, and purchasing patterns
- **Predicts customer segments** for new customers using machine learning
- **Provides actionable insights** through interactive dashboards and visualizations
- **Exports business-ready data** for Tableau and other BI tools

### Key Capabilities

âœ… **RFM Analysis** - Recency, Frequency, Monetary segmentation  
âœ… **Advanced Feature Engineering** - 60+ behavioral and demographic features  
âœ… **K-Means Clustering** - Optimized customer segmentation  
âœ… **Predictive Modeling** - Random Forest, Gradient Boosting, Logistic Regression  
âœ… **Interactive Dashboard** - Real-time predictions with Streamlit  
âœ… **Tableau Integration** - Pre-built datasets and dashboard templates  

---

## âœ¨ Features

### ğŸ” Analysis Capabilities

- **Customer Segmentation**: K-Means clustering with 4-5 distinct customer segments
- **RFM Scoring**: Automated Recency, Frequency, Monetary value analysis
- **Behavioral Analysis**: Purchase patterns, product preferences, channel usage
- **Predictive Modeling**: 95%+ accuracy in segment prediction
- **Dimensionality Reduction**: PCA for visualization and feature compression

### ğŸ“Š Visualization & Reporting

- **Interactive Streamlit Dashboard**: Real-time customer prediction and analysis
- **Tableau Exports**: 7+ pre-calculated datasets with data dictionary
- **Comprehensive Reports**: Statistical summaries, feature importance, model metrics
- **Publication-Ready Plots**: High-resolution visualizations for presentations

### ğŸ¯ Business Value

- **Targeted Marketing**: Personalized campaigns for each segment
- **Resource Optimization**: Focus on high-value customers
- **Churn Prevention**: Early identification of at-risk customers
- **Product Development**: Understand preferences by segment
- **Revenue Growth**: Maximize customer lifetime value

---

## ğŸ“ Project Structure

```
customer-segmentation/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                              # Original dataset
â”‚   â”‚   â””â”€â”€ marketing_campaign.csv
â”‚   â””â”€â”€ processed/                        # Processed datasets
â”‚       â”œâ”€â”€ step1_cleaned_data.csv
â”‚       â”œâ”€â”€ step2_rfm_analyzed.csv
â”‚       â”œâ”€â”€ step3_features_engineered.csv
â”‚       â”œâ”€â”€ step4_clustered_customers.csv
â”‚       â”œâ”€â”€ step5_dimensionality_reduced.csv
â”‚       â”œâ”€â”€ step6_evaluated_clusters.csv
â”‚       â””â”€â”€ step7_profiled_segments.csv
â”‚
â”œâ”€â”€ notebooks/                            # Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ step1_data_collection_preparation.ipynb
â”‚   â”œâ”€â”€ step2_rfm_analysis.ipynb
â”‚   â”œâ”€â”€ step3_feature_engineering.ipynb
â”‚   â”œâ”€â”€ step4_ml_clustering.ipynb
â”‚   â”œâ”€â”€ step5_dimensionality_reduction.ipynb
â”‚   â”œâ”€â”€ step6_model_evaluation.ipynb
â”‚   â”œâ”€â”€ step7_segment_profiling.ipynb
â”‚   â””â”€â”€ step8_predictive_modeling.ipynb
â”‚
â”‚   â””â”€â”€ outputs/                          # Analysis outputs
â”‚       â”œâ”€â”€ figures/                      # Visualizations (PNG)
â”‚       â”œâ”€â”€ models/                       # Trained models (PKL)
â”‚       â”‚   â”œâ”€â”€ kmeans_model.pkl
â”‚       â”‚   â”œâ”€â”€ scaler.pkl
â”‚       â”‚   â”œâ”€â”€ pca_2d.pkl
â”‚       â”‚   â”œâ”€â”€ best_model_random_forest.pkl
â”‚       â”‚   â””â”€â”€ model_config.pkl
â”‚       â””â”€â”€ reports/                      # Analysis reports (CSV)
â”‚
â”œâ”€â”€ scripts/                              # Python scripts
â”‚   â””â”€â”€ step10_create_tableau_export.py
â”‚
â”œâ”€â”€ tableau_exports/                      # Tableau-ready datasets
â”‚   â”œâ”€â”€ 00_data_dictionary.csv
â”‚   â”œâ”€â”€ 01_customer_segmentation_main.csv
â”‚   â”œâ”€â”€ 02_cluster_summary.csv
â”‚   â”œâ”€â”€ 03_rfm_segment_summary.csv
â”‚   â”œâ”€â”€ 04_product_category_by_cluster.csv
â”‚   â”œâ”€â”€ 05_demographics_by_cluster.csv
â”‚   â”œâ”€â”€ 06_enrollment_timeseries.csv
â”‚   â”œâ”€â”€ 07_channel_performance.csv
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ app.py                                # Streamlit dashboard
â”œâ”€â”€ requirements.txt                      # Python dependencies
â”œâ”€â”€ README.md                             # This file
â””â”€â”€ LICENSE                               # MIT License

```

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- Git

### Setup Instructions

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/customer-segmentation.git
cd customer-segmentation
```

2. **Create virtual environment** (recommended)

```bash
# Using venv
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Or using conda
conda create -n customer-seg python=3.8
conda activate customer-seg
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Download dataset**

Download the [Customer Personality Analysis dataset](https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis) from Kaggle and place it in `data/raw/marketing_campaign.csv`

---

## ğŸ’» Usage

### Running the Analysis Pipeline

Execute notebooks in order:

```bash
# Step 1: Data Preparation
jupyter notebook notebooks/step1_data_collection_preparation.ipynb

# Step 2: RFM Analysis
jupyter notebook notebooks/step2_rfm_analysis.ipynb

# Step 3: Feature Engineering
jupyter notebook notebooks/step3_feature_engineering.ipynb

# Step 4: Clustering
jupyter notebook notebooks/step4_ml_clustering.ipynb

# Step 5: Dimensionality Reduction
jupyter notebook notebooks/step5_dimensionality_reduction.ipynb

# Step 6: Model Evaluation
jupyter notebook notebooks/step6_model_evaluation.ipynb

# Step 7: Segment Profiling
jupyter notebook notebooks/step7_segment_profiling.ipynb

# Step 8: Predictive Modeling
jupyter notebook notebooks/step9_predictive_modeling.ipynb
```

### Creating Tableau Exports

```bash
python scripts/step10_create_tableau_export.py
```

### Running Streamlit Dashboard

```bash
streamlit run app.py
```

The dashboard will open automatically at `http://localhost:8501`

---

## ğŸ”„ Pipeline Steps

### Step 1: Data Collection & Preparation
- Load and explore raw customer data
- Handle missing values and outliers
- Data type conversions and validation
- Initial exploratory data analysis (EDA)

**Key Outputs**: Clean dataset, data quality report

### Step 2: RFM Analysis
- Calculate Recency, Frequency, Monetary metrics
- Score customers on 1-5 scale for each dimension
- Create RFM segments (Champions, Loyal, At Risk, etc.)
- Visualize RFM distributions

**Key Outputs**: RFM scores, segment labels, distribution plots

### Step 3: Feature Engineering
- Create 60+ behavioral features:
  - Demographics (Age, Income, Family Size)
  - Spending patterns (Order value, frequency)
  - Product preferences (Wine, Meat, Product diversity)
  - Channel usage (Web, Store, Catalog)
  - Engagement metrics (Campaigns, Web visits)
  - Customer value (CLV, Value score)
- Feature scaling and normalization

**Key Outputs**: Engineered features dataset, correlation analysis

### Step 4: Machine Learning Clustering
- Determine optimal number of clusters (Elbow, Silhouette)
- K-Means clustering algorithm
- Cluster assignment and validation
- Initial cluster profiling

**Key Outputs**: Cluster labels, centroids, validation metrics

### Step 5: Dimensionality Reduction
- Principal Component Analysis (PCA)
- Variance analysis (90%, 95%, 99% thresholds)
- 2D/3D visualizations
- Feature importance in components

**Key Outputs**: PCA components, variance plots, feature loadings

### Step 6: Model Evaluation
- Clustering quality metrics:
  - Silhouette Score: 0.XX
  - Calinski-Harabasz Score: XXX
  - Davies-Bouldin Score: X.XX
- Cluster stability analysis
- Feature importance (ANOVA F-test)
- Confusion matrix and performance metrics

**Key Outputs**: Evaluation reports, quality metrics, stability scores

### Step 7: Segment Profiling & Interpretation
- Detailed cluster characterization
- Demographics by segment
- RFM profiles per segment
- Product and channel preferences
- Engagement patterns
- Business personas creation

**Key Outputs**: Segment profiles, personas, recommendation reports

### Step 8: Predictive Modeling
- Train classification models:
  - Random Forest (Best: 95%+ accuracy)
  - Gradient Boosting
  - Logistic Regression
- Feature importance analysis
- Cross-validation (5-fold)
- Prediction confidence scoring

**Key Outputs**: Trained models, performance reports, feature rankings

### Step 10: Tableau Export
- Create business-ready datasets
- Generate aggregate tables
- Add derived dimensions
- Create data dictionary
- Package dashboard templates

**Key Outputs**: 7 CSV files, README, Tableau starter workbook

---

## ğŸ“Š Results

### Segmentation Performance

| Metric | Value |
|--------|-------|
|**Silhouette Score**| |0.3975|
|**Calinski-Harabasz Score**| |2064.24|
|**Davies-Bouldin Score**| |0.7016|
 |**Average Stability**||0.893|
| **Number of Clusters** | 1-2 |
| **Largest Cluster** | 70.7% of customers |
| **Smallest Cluster** | 29.3% of customers |
| **Cluster Balance** | imbalanced |

### Prediction Accuracy

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| **Random Forest** | 95.X% | 0.9XX | 0.9XX | 0.9XX |
| Gradient Boosting | 94.X% | 0.9XX | 0.9XX | 0.9XX |
| Logistic Regression | 92.X% | 0.9XX | 0.9XX | 0.9XX |

### Key Customer Segments

**Segment 0: Premium Customers** (70.7%)
- High income, high spending
- Prefers wine and premium products
- Multi-channel shoppers
- High campaign response rate

**Segment 1: Value Seekers** (29.3%)
- Moderate income, deal-oriented
- High frequency, lower AOV
- Web-focused shoppers
- Price-sensitive


## ğŸ¨ Dashboards

### Streamlit Interactive Dashboard

**Features:**
- ğŸ  **Dashboard**: Overview of segments and key metrics
- ğŸ”® **Predict Customer**: Real-time segment prediction
- ğŸ“Š **Cluster Analysis**: Deep dive into each segment
- ğŸ“ˆ **Model Performance**: Evaluation metrics and feature importance
- â„¹ï¸ **About**: Methodology and documentation

**Screenshots:**

![Dashboard Overview](https://via.placeholder.com/800x400/667eea/ffffff?text=Dashboard+Screenshot)

### Tableau Dashboards

**6 Pre-designed Dashboard Templates:**

1. **Executive Summary** - KPIs and segment distribution
2. **Segmentation Overview** - PCA visualization and characteristics
3. **RFM Analysis** - Recency, Frequency, Monetary insights
4. **Product & Channel Performance** - Category and channel analysis
5. **Customer Journey** - Tenure and engagement tracking
6. **Value Analysis** - CLV and revenue concentration

---

## ğŸ› ï¸ Technologies

### Core Libraries

| Category | Technologies |
|----------|-------------|
| **Data Processing** | Pandas, NumPy |
| **Machine Learning** | Scikit-learn |
| **Visualization** | Matplotlib, Seaborn, Plotly |
| **Dashboard** | Streamlit |
| **Statistical Analysis** | SciPy, Statsmodels |

### Models & Algorithms

- **Clustering**: K-Means
- **Classification**: Random Forest, Gradient Boosting, Logistic Regression
- **Dimensionality Reduction**: PCA
- **Feature Selection**: ANOVA F-test, Feature Importance

### Development Tools

- Jupyter Notebook for analysis
- Git for version control
- Python 3.8+ environment

---

## ğŸ“Š Dataset

**Source**: [Customer Personality Analysis - Kaggle](https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis)

### Dataset Overview

- **Rows**: 2,240 customers
- **Original Features**: 29
- **Engineered Features**: 60+
- **Time Period**: 2012-2014

### Key Variables

**Demographics**: Age, Income, Education, Marital Status, Children  
**Spending**: Wine, Fruits, Meat, Fish, Sweets, Gold/Premium  
**Purchases**: Web, Catalog, Store, Deals  
**Campaigns**: 5 campaigns + response tracking  
**Engagement**: Web visits, Complaints, Recency

---

## ğŸ“ˆ Business Applications

### Marketing Strategies by Segment

**Premium Customers**
- Exclusive offers and early access
- Premium product promotions
- Personalized recommendations

**Value Seekers**
- Bundle deals and discounts
- Loyalty program benefits
- Flash sales notifications

**Occasional Buyers**
- Re-engagement campaigns
- Win-back offers
- Simplified purchase process

### ROI Expectations

- **Targeted Campaigns**: 30-50% higher response rates
- **Customer Retention**: 15-25% improvement
- **Revenue per Customer**: 20-40% increase
- **Marketing Efficiency**: 25-35% cost reduction

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Development Guidelines

- Follow PEP 8 style guide
- Add docstrings to functions
- Include unit tests for new features
- Update documentation as needed

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Authors

**Your Name**
- GitHub: [@yourusername](https://github.com/yourusername)
- LinkedIn: www.linkedin.com/in/zeinab-mahfouz

- Email: zeinab.h.mahfouz@gmail.com

---

## ğŸ™ Acknowledgments

- Dataset provided by [Kaggle - Customer Personality Analysis](https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis)
- Inspired by RFM analysis and customer segmentation best practices
- Built with open-source libraries and tools

---

## ğŸ“ Support

For questions or issues:

1. Check existing [Issues](https://github.com/yourusername/customer-segmentation/issues)
2. Create a new issue with detailed description
3. Reach out via email for urgent matters

---

## ğŸ—ºï¸ Roadmap

### Future Enhancements

- [ ] Add time-series forecasting for customer behavior
- [ ] Implement A/B testing framework
- [ ] Add customer churn prediction model
- [ ] Create REST API for predictions
- [ ] Deploy dashboard to cloud (Heroku/AWS)
- [ ] Add automated model retraining pipeline
- [ ] Integrate with CRM systems
- [ ] Build email campaign generator
- [ ] Add multilingual support
- [ ] Create mobile-responsive dashboard

---

## ğŸ“š References

1. **RFM Analysis**: [RFM Analysis for Successful Customer Segmentation](https://www.optimove.com/resources/learning-center/rfm-analysis-for-customer-segmentation)
2. **K-Means Clustering**: Scikit-learn Documentation
3. **Customer Segmentation**: Harvard Business Review articles on customer analytics
4. **Feature Engineering**: Applied Predictive Modeling (Kuhn & Johnson)

---

## â­ Star History

If you find this project useful, please consider giving it a star! â­

[![Star History Chart](https://api.star-history.com/svg?repos=yourusername/customer-segmentation&type=Date)](https://star-history.com/#yourusername/customer-segmentation&Date)

---

<div align="center">

**Built with â¤ï¸ using Python, Machine Learning, and Data Science**

[Report Bug](https://github.com/yourusername/customer-segmentation/issues) Â· [Request Feature](https://github.com/yourusername/customer-segmentation/issues)

</div>
